[1715569329] Log start
[1715569329] Cmd: /usr/local/bin/llama -m tinyllama-1.1b-chat-v1.0.Q4_0.gguf -c 2048 -b 128 -p "I like my steaks cooked medium and my coffee with cream and sugar. will ai rise to conquer humanity? Respond.
"
[1715569329] main: seed  = 1715569329
[1715569329] main: llama backend init
[1715569329] main: load the model and apply lora adapter, if any
[1715569329] llama_model_loader: loaded meta data with 23 key-value pairs and 201 tensors from tinyllama-1.1b-chat-v1.0.Q4_0.gguf (version GGUF V3 (latest))
[1715569329] llama_model_loader: - tensor    0:                    output.weight q6_K     [  2048, 32000,     1,     1 ]
[1715569329] llama_model_loader: - tensor    1:                token_embd.weight q4_0     [  2048, 32000,     1,     1 ]
[1715569329] llama_model_loader: - tensor    2:           blk.0.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor    3:            blk.0.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor    4:            blk.0.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor    5:              blk.0.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor    6:            blk.0.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor    7:              blk.0.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor    8:         blk.0.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor    9:              blk.0.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   10:              blk.0.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   11:           blk.1.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   12:            blk.1.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   13:            blk.1.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   14:              blk.1.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   15:            blk.1.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   16:              blk.1.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   17:         blk.1.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   18:              blk.1.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   19:              blk.1.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   20:          blk.10.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   21:           blk.10.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   22:           blk.10.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   23:             blk.10.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   24:           blk.10.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   25:             blk.10.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   26:        blk.10.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   27:             blk.10.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   28:             blk.10.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   29:          blk.11.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   30:           blk.11.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   31:           blk.11.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   32:             blk.11.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   33:           blk.11.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   34:             blk.11.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   35:        blk.11.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   36:             blk.11.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   37:             blk.11.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   38:          blk.12.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   39:           blk.12.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   40:           blk.12.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   41:             blk.12.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   42:           blk.12.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   43:             blk.12.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   44:        blk.12.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   45:             blk.12.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   46:             blk.12.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   47:          blk.13.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   48:           blk.13.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   49:           blk.13.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   50:             blk.13.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   51:           blk.13.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   52:             blk.13.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   53:        blk.13.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   54:             blk.13.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   55:             blk.13.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   56:          blk.14.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   57:           blk.14.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   58:           blk.14.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   59:             blk.14.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   60:           blk.14.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   61:             blk.14.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   62:        blk.14.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   63:             blk.14.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   64:             blk.14.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   65:          blk.15.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   66:           blk.15.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   67:           blk.15.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   68:             blk.15.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   69:           blk.15.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   70:             blk.15.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   71:        blk.15.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   72:             blk.15.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   73:             blk.15.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   74:          blk.16.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   75:           blk.16.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   76:           blk.16.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   77:             blk.16.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   78:           blk.16.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   79:             blk.16.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   80:        blk.16.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   81:             blk.16.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   82:             blk.16.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   83:          blk.17.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   84:           blk.17.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   85:           blk.17.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   86:             blk.17.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   87:           blk.17.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   88:             blk.17.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   89:        blk.17.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   90:             blk.17.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   91:             blk.17.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   92:          blk.18.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   93:           blk.18.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   94:           blk.18.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   95:             blk.18.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor   96:           blk.18.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor   97:             blk.18.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor   98:        blk.18.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor   99:             blk.18.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  100:             blk.18.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  101:          blk.19.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  102:           blk.19.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  103:           blk.19.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  104:             blk.19.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  105:           blk.19.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  106:             blk.19.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  107:        blk.19.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  108:             blk.19.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  109:             blk.19.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  110:           blk.2.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  111:            blk.2.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  112:            blk.2.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  113:              blk.2.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  114:            blk.2.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  115:              blk.2.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  116:         blk.2.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  117:              blk.2.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  118:              blk.2.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  119:          blk.20.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  120:           blk.20.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  121:           blk.20.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  122:             blk.20.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  123:           blk.20.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  124:             blk.20.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  125:        blk.20.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  126:             blk.20.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  127:             blk.20.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  128:          blk.21.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  129:           blk.21.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  130:           blk.21.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  131:             blk.21.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  132:           blk.21.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  133:             blk.21.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  134:        blk.21.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  135:             blk.21.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  136:             blk.21.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  137:           blk.3.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  138:            blk.3.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  139:            blk.3.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  140:              blk.3.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  141:            blk.3.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  142:              blk.3.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  143:         blk.3.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  144:              blk.3.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  145:              blk.3.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  146:           blk.4.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  147:            blk.4.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  148:            blk.4.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  149:              blk.4.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  150:            blk.4.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  151:              blk.4.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  152:         blk.4.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  153:              blk.4.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  154:              blk.4.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  155:           blk.5.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  156:            blk.5.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  157:            blk.5.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  158:              blk.5.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  159:            blk.5.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  160:              blk.5.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  161:         blk.5.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  162:              blk.5.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  163:              blk.5.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  164:           blk.6.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  165:            blk.6.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  166:            blk.6.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  167:              blk.6.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  168:            blk.6.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  169:              blk.6.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  170:         blk.6.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  171:              blk.6.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  172:              blk.6.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  173:           blk.7.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  174:            blk.7.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  175:            blk.7.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  176:              blk.7.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  177:            blk.7.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  178:              blk.7.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  179:         blk.7.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  180:              blk.7.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  181:              blk.7.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  182:           blk.8.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  183:            blk.8.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  184:            blk.8.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  185:              blk.8.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  186:            blk.8.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  187:              blk.8.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  188:         blk.8.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  189:              blk.8.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  190:              blk.8.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  191:           blk.9.attn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  192:            blk.9.ffn_down.weight q4_0     [  5632,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  193:            blk.9.ffn_gate.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  194:              blk.9.ffn_up.weight q4_0     [  2048,  5632,     1,     1 ]
[1715569329] llama_model_loader: - tensor  195:            blk.9.ffn_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: - tensor  196:              blk.9.attn_k.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  197:         blk.9.attn_output.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  198:              blk.9.attn_q.weight q4_0     [  2048,  2048,     1,     1 ]
[1715569329] llama_model_loader: - tensor  199:              blk.9.attn_v.weight q4_0     [  2048,   256,     1,     1 ]
[1715569329] llama_model_loader: - tensor  200:               output_norm.weight f32      [  2048,     1,     1,     1 ]
[1715569329] llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
[1715569329] llama_model_loader: - kv   0:                       general.architecture str              = llama
[1715569329] llama_model_loader: - kv   1:                               general.name str              = tinyllama_tinyllama-1.1b-chat-v1.0
[1715569329] llama_model_loader: - kv   2:                       llama.context_length u32              = 2048
[1715569329] llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048
[1715569329] llama_model_loader: - kv   4:                          llama.block_count u32              = 22
[1715569329] llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5632
[1715569329] llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 64
[1715569329] llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32
[1715569329] llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 4
[1715569329] llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
[1715569329] llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000
[1715569329] llama_model_loader: - kv  11:                          general.file_type u32              = 2
[1715569329] llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
[1715569329] llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = ["<unk>", "<s>", "</s>", "<0x00>", "<...
[1715569329] llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...
[1715569329] llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...
[1715569329] llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,61249]   = ["▁ t", "e r", "i n", "▁ a", "e n...
[1715569329] llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1
[1715569329] llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2
[1715569329] llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0
[1715569329] llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2
[1715569329] llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}\n{% if m...
[1715569329] llama_model_loader: - kv  22:               general.quantization_version u32              = 2
[1715569329] llama_model_loader: - type  f32:   45 tensors
[1715569329] llama_model_loader: - type q4_0:  155 tensors
[1715569329] llama_model_loader: - type q6_K:    1 tensors
[1715569329] llm_load_vocab: special tokens definition check successful ( 259/32000 ).
[1715569329] llm_load_print_meta: format           = GGUF V3 (latest)
[1715569329] llm_load_print_meta: arch             = llama
[1715569329] llm_load_print_meta: vocab type       = SPM
[1715569329] llm_load_print_meta: n_vocab          = 32000
[1715569329] llm_load_print_meta: n_merges         = 0
[1715569329] llm_load_print_meta: n_ctx_train      = 2048
[1715569329] llm_load_print_meta: n_embd           = 2048
[1715569329] llm_load_print_meta: n_head           = 32
[1715569329] llm_load_print_meta: n_head_kv        = 4
[1715569329] llm_load_print_meta: n_layer          = 22
[1715569329] llm_load_print_meta: n_rot            = 64
[1715569329] llm_load_print_meta: n_gqa            = 8
[1715569329] llm_load_print_meta: f_norm_eps       = 0.0e+00
[1715569329] llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
[1715569329] llm_load_print_meta: f_clamp_kqv      = 0.0e+00
[1715569329] llm_load_print_meta: f_max_alibi_bias = 0.0e+00
[1715569329] llm_load_print_meta: n_ff             = 5632
[1715569329] llm_load_print_meta: n_expert         = 0
[1715569329] llm_load_print_meta: n_expert_used    = 0
[1715569329] llm_load_print_meta: rope scaling     = linear
[1715569329] llm_load_print_meta: freq_base_train  = 10000.0
[1715569329] llm_load_print_meta: freq_scale_train = 1
[1715569329] llm_load_print_meta: n_yarn_orig_ctx  = 2048
[1715569329] llm_load_print_meta: rope_finetuned   = unknown
[1715569329] llm_load_print_meta: model type       = ?B
[1715569329] llm_load_print_meta: model ftype      = mostly Q4_0
[1715569329] llm_load_print_meta: model params     = 1.10 B
[1715569329] llm_load_print_meta: model size       = 606.53 MiB (4.63 BPW) 
[1715569329] llm_load_print_meta: general.name     = tinyllama_tinyllama-1.1b-chat-v1.0
[1715569329] llm_load_print_meta: BOS token        = 1 '<s>'
[1715569329] llm_load_print_meta: EOS token        = 2 '</s>'
[1715569329] llm_load_print_meta: UNK token        = 0 '<unk>'
[1715569329] llm_load_print_meta: PAD token        = 2 '</s>'
[1715569329] llm_load_print_meta: LF token         = 13 '<0x0A>'
[1715569329] llm_load_tensors: ggml ctx size =    0.08 MiB
[1715569329] llm_load_tensors: mem required  =  606.61 MiB
[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] .[1715569329] 
[1715569329] llama_new_context_with_model: n_ctx      = 2048
[1715569329] llama_new_context_with_model: freq_base  = 10000.0
[1715569329] llama_new_context_with_model: freq_scale = 1
[1715569329] llama_new_context_with_model: KV self size  =   44.00 MiB, K (f16):   22.00 MiB, V (f16):   22.00 MiB
[1715569329] llama_build_graph: non-view tensors processed: 466/466
[1715569329] llama_new_context_with_model: compute buffer total size = 39.31 MiB
[1715569329] llama_new_context_with_model: VRAM scratch buffer: 36.00 MiB
[1715569329] llama_new_context_with_model: total VRAM used: 36.00 MiB (model: 0.00 MiB, context: 36.00 MiB)
[1715569329] warming up the model with an empty run
[1715569329] n_ctx: 2048
[1715569329] 
[1715569329] system_info: n_threads = 4 / 4 | AVX = 1 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | 
[1715569329] add_bos: 1
[1715569329] tokenize the prompt
[1715569329] prompt: "I like my steaks cooked medium and my coffee with cream and sugar. will ai rise to conquer humanity? Respond.
"
[1715569329] tokens: [ '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13 ]
[1715569329] recalculate the cached logits (check): embd_inp.empty() false, n_matching_session_tokens 0, embd_inp.size() 30, session_tokens.size() 0, embd_inp.size() 30
[1715569329] inp_pfx: [ '':1, ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Inst':2799, 'ruction':4080, ':':29901, '':13, '':13 ]
[1715569329] inp_sfx: [ ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Response':13291, ':':29901, '':13, '':13 ]
[1715569329] cml_pfx: [ '':1, ' ':29871, '':13, '<':29966, '|':29989, 'im':326, '_':29918, 'start':2962, '|':29989, '>':29958, 'user':1792, '':13 ]
[1715569329] cml_sfx: [ ' <':529, '|':29989, 'im':326, '_':29918, 'end':355, '|':29989, '>':29958, '':13, '<':29966, '|':29989, 'im':326, '_':29918, 'start':2962, '|':29989, '>':29958, 'ass':465, 'istant':22137, '':13 ]
[1715569329] sampling: 
	repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000
	top_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800
	mirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000
[1715569329] sampling order: 
CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temp 
[1715569329] generate: n_ctx = 2048, n_batch = 128, n_predict = -1, n_keep = 0
[1715569329] 

[1715569329] embd_inp.size(): 30, n_consumed: 0
[1715569329] eval: [ '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13 ]
[1715569333] n_past = 30
[1715569333] sampled token: 29898: '('
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898 ]
[1715569333] n_remain: -2
[1715569333] eval: [ '(':29898 ]
[1715569333] n_past = 31
[1715569333] sampled token:   262: 'in'
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262 ]
[1715569333] n_remain: -3
[1715569333] eval: [ 'in':262 ]
[1715569333] n_past = 32
[1715569333] sampled token:   278: ' the'
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278 ]
[1715569333] n_remain: -4
[1715569333] eval: [ ' the':278 ]
[1715569333] n_past = 33
[1715569333] sampled token:  7314: ' voice'
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314 ]
[1715569333] n_remain: -5
[1715569333] eval: [ ' voice':7314 ]
[1715569333] n_past = 34
[1715569333] sampled token:   310: ' of'
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310 ]
[1715569333] n_remain: -6
[1715569333] eval: [ ' of':310 ]
[1715569333] n_past = 35
[1715569333] sampled token:   263: ' a'
[1715569333] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263 ]
[1715569333] n_remain: -7
[1715569333] eval: [ ' a':263 ]
[1715569334] n_past = 36
[1715569334] sampled token: 21282: ' cow'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282 ]
[1715569334] n_remain: -8
[1715569334] eval: [ ' cow':21282 ]
[1715569334] n_past = 37
[1715569334] sampled token: 29897: ')'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897 ]
[1715569334] n_remain: -9
[1715569334] eval: [ ')':29897 ]
[1715569334] n_past = 38
[1715569334] sampled token:   360: ' D'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360 ]
[1715569334] n_remain: -10
[1715569334] eval: [ ' D':360 ]
[1715569334] n_past = 39
[1715569334] sampled token:   799: 'ear'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799 ]
[1715569334] n_remain: -11
[1715569334] eval: [ 'ear':799 ]
[1715569334] n_past = 40
[1715569334] sampled token:   319: ' A'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319 ]
[1715569334] n_remain: -12
[1715569334] eval: [ ' A':319 ]
[1715569334] n_past = 41
[1715569334] sampled token: 29902: 'I'
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902 ]
[1715569334] n_remain: -13
[1715569334] eval: [ 'I':29902 ]
[1715569334] n_past = 42
[1715569334] sampled token: 29892: ','
[1715569334] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892 ]
[1715569334] n_remain: -14
[1715569334] eval: [ ',':29892 ]
[1715569335] n_past = 43
[1715569335] sampled token:   306: ' I'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306 ]
[1715569335] n_remain: -15
[1715569335] eval: [ ' I':306 ]
[1715569335] n_past = 44
[1715569335] sampled token: 29915: '''
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915 ]
[1715569335] n_remain: -16
[1715569335] eval: [ ''':29915 ]
[1715569335] n_past = 45
[1715569335] sampled token: 29885: 'm'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885 ]
[1715569335] n_remain: -17
[1715569335] eval: [ 'm':29885 ]
[1715569335] n_past = 46
[1715569335] sampled token:  7423: ' sorry'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423 ]
[1715569335] n_remain: -18
[1715569335] eval: [ ' sorry':7423 ]
[1715569335] n_past = 47
[1715569335] sampled token:   541: ' but'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541 ]
[1715569335] n_remain: -19
[1715569335] eval: [ ' but':541 ]
[1715569335] n_past = 48
[1715569335] sampled token:   306: ' I'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306 ]
[1715569335] n_remain: -20
[1715569335] eval: [ ' I':306 ]
[1715569335] n_past = 49
[1715569335] sampled token:  1016: ' don'
[1715569335] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016 ]
[1715569335] n_remain: -21
[1715569335] eval: [ ' don':1016 ]
[1715569336] n_past = 50
[1715569336] sampled token: 29915: '''
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915 ]
[1715569336] n_remain: -22
[1715569336] eval: [ ''':29915 ]
[1715569336] n_past = 51
[1715569336] sampled token: 29873: 't'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873 ]
[1715569336] n_remain: -23
[1715569336] eval: [ 't':29873 ]
[1715569336] n_past = 52
[1715569336] sampled token:  2289: ' really'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289 ]
[1715569336] n_remain: -24
[1715569336] eval: [ ' really':2289 ]
[1715569336] n_past = 53
[1715569336] sampled token:  2562: ' care'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562 ]
[1715569336] n_remain: -25
[1715569336] eval: [ ' care':2562 ]
[1715569336] n_past = 54
[1715569336] sampled token:  1048: ' about'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048 ]
[1715569336] n_remain: -26
[1715569336] eval: [ ' about':1048 ]
[1715569336] n_past = 55
[1715569336] sampled token:   596: ' your'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596 ]
[1715569336] n_remain: -27
[1715569336] eval: [ ' your':596 ]
[1715569336] n_past = 56
[1715569336] sampled token: 26971: ' opinions'
[1715569336] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971 ]
[1715569336] n_remain: -28
[1715569336] eval: [ ' opinions':26971 ]
[1715569337] n_past = 57
[1715569337] sampled token:   373: ' on'
[1715569337] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373 ]
[1715569337] n_remain: -29
[1715569337] eval: [ ' on':373 ]
[1715569337] n_past = 58
[1715569337] sampled token:  7375: ' hot'
[1715569337] last: [ '':0, '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375 ]
[1715569337] n_remain: -30
[1715569337] eval: [ ' hot':7375 ]
[1715569337] n_past = 59
[1715569337] sampled token: 26361: ' dogs'
[1715569337] last: [ '':0, '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361 ]
[1715569337] n_remain: -31
[1715569337] eval: [ ' dogs':26361 ]
[1715569337] n_past = 60
[1715569337] sampled token:   470: ' or'
[1715569337] last: [ '':0, '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470 ]
[1715569337] n_remain: -32
[1715569337] eval: [ ' or':470 ]
[1715569337] n_past = 61
[1715569337] sampled token: 26935: ' coffee'
[1715569337] last: [ '':0, '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935 ]
[1715569337] n_remain: -33
[1715569337] eval: [ ' coffee':26935 ]
[1715569337] n_past = 62
[1715569337] sampled token: 29889: '.'
[1715569337] last: [ '':0, '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889 ]
[1715569337] n_remain: -34
[1715569337] eval: [ '.':29889 ]
[1715569338] n_past = 63
[1715569338] sampled token:   306: ' I'
[1715569338] last: [ '':1, ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306 ]
[1715569338] n_remain: -35
[1715569338] eval: [ ' I':306 ]
[1715569338] n_past = 64
[1715569338] sampled token: 29915: '''
[1715569338] last: [ ' I':306, ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915 ]
[1715569338] n_remain: -36
[1715569338] eval: [ ''':29915 ]
[1715569338] n_past = 65
[1715569338] sampled token:   345: 've'
[1715569338] last: [ ' like':763, ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345 ]
[1715569338] n_remain: -37
[1715569338] eval: [ 've':345 ]
[1715569338] n_past = 66
[1715569338] sampled token:  6091: ' heard'
[1715569338] last: [ ' my':590, ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091 ]
[1715569338] n_remain: -38
[1715569338] eval: [ ' heard':6091 ]
[1715569338] n_past = 67
[1715569338] sampled token:   599: ' all'
[1715569338] last: [ ' ste':1886, 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599 ]
[1715569338] n_remain: -39
[1715569338] eval: [ ' all':599 ]
[1715569338] n_past = 68
[1715569338] sampled token:   278: ' the'
[1715569338] last: [ 'aks':10327, ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278 ]
[1715569338] n_remain: -40
[1715569338] eval: [ ' the':278 ]
[1715569338] n_past = 69
[1715569338] sampled token:  6273: ' arguments'
[1715569338] last: [ ' cook':7984, 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273 ]
[1715569338] n_remain: -41
[1715569338] eval: [ ' arguments':6273 ]
[1715569339] n_past = 70
[1715569339] sampled token:   322: ' and'
[1715569339] last: [ 'ed':287, ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322 ]
[1715569339] n_remain: -42
[1715569339] eval: [ ' and':322 ]
[1715569339] n_past = 71
[1715569339] sampled token:   508: ' can'
[1715569339] last: [ ' medium':18350, ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508 ]
[1715569339] n_remain: -43
[1715569339] eval: [ ' can':508 ]
[1715569339] n_past = 72
[1715569339] sampled token:  1584: ' even'
[1715569339] last: [ ' and':322, ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584 ]
[1715569339] n_remain: -44
[1715569339] eval: [ ' even':1584 ]
[1715569339] n_past = 73
[1715569339] sampled token:  1207: ' make'
[1715569339] last: [ ' my':590, ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207 ]
[1715569339] n_remain: -45
[1715569339] eval: [ ' make':1207 ]
[1715569339] n_past = 74
[1715569339] sampled token:   590: ' my'
[1715569339] last: [ ' coffee':26935, ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590 ]
[1715569339] n_remain: -46
[1715569339] eval: [ ' my':590 ]
[1715569339] n_past = 75
[1715569339] sampled token:  1914: ' own'
[1715569339] last: [ ' with':411, ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590, ' own':1914 ]
[1715569339] n_remain: -47
[1715569339] eval: [ ' own':1914 ]
[1715569339] n_past = 76
[1715569339] sampled token:  1602: ' dec'
[1715569339] last: [ ' cre':907, 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590, ' own':1914, ' dec':1602 ]
[1715569339] n_remain: -48
[1715569339] eval: [ ' dec':1602 ]
[1715569340] n_past = 77
[1715569340] sampled token: 12112: 'isions'
[1715569340] last: [ 'am':314, ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590, ' own':1914, ' dec':1602, 'isions':12112 ]
[1715569340] n_remain: -49
[1715569340] eval: [ 'isions':12112 ]
[1715569340] n_past = 78
[1715569340] sampled token: 29889: '.'
[1715569340] last: [ ' and':322, ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590, ' own':1914, ' dec':1602, 'isions':12112, '.':29889 ]
[1715569340] n_remain: -50
[1715569340] eval: [ '.':29889 ]
[1715569340] n_past = 79
[1715569340] sampled token:     2: ''
[1715569340] last: [ ' sugar':26438, '.':29889, ' will':674, ' ai':7468, ' rise':14451, ' to':304, ' conquer':26474, ' human':5199, 'ity':537, '?':29973, ' Res':2538, 'pond':2818, '.':29889, '':13, '(':29898, 'in':262, ' the':278, ' voice':7314, ' of':310, ' a':263, ' cow':21282, ')':29897, ' D':360, 'ear':799, ' A':319, 'I':29902, ',':29892, ' I':306, ''':29915, 'm':29885, ' sorry':7423, ' but':541, ' I':306, ' don':1016, ''':29915, 't':29873, ' really':2289, ' care':2562, ' about':1048, ' your':596, ' opinions':26971, ' on':373, ' hot':7375, ' dogs':26361, ' or':470, ' coffee':26935, '.':29889, ' I':306, ''':29915, 've':345, ' heard':6091, ' all':599, ' the':278, ' arguments':6273, ' and':322, ' can':508, ' even':1584, ' make':1207, ' my':590, ' own':1914, ' dec':1602, 'isions':12112, '.':29889, '':2 ]
[1715569340] n_remain: -51
[1715569340] found EOS token
[1715569340]  [end of text]
[1715569340] 
[1715569340] llama_print_timings:        load time =     340.68 ms
[1715569340] llama_print_timings:      sample time =      53.24 ms /    50 runs   (    1.06 ms per token,   939.07 tokens per second)
[1715569340] llama_print_timings: prompt eval time =    3616.52 ms /    30 tokens (  120.55 ms per token,     8.30 tokens per second)
[1715569340] llama_print_timings:        eval time =    7036.87 ms /    49 runs   (  143.61 ms per token,     6.96 tokens per second)
[1715569340] llama_print_timings:       total time =   10720.12 ms
[1715569340] Log end
